## Deploy the LLM+RAG Demo

To deploy the demo, run the following command:

```sh
./deploy.sh
```

This script performs the following actions:
- Clone the repo `https://github.com/kusumachalasani/llm-rag-deployment.git`.
- Uses namespace `ic-shared-rag-llm` for the demo.
- Includes a custom GenAI image.
- Deploys the Postgres database.
- Deploys the LLM using the Minstral AI model.
- Deploys the Gradio service for Q&A.
- Ingests several sources of data into the database for RAG (Retrieval-Augmented Generation).

## Running the Load

``` 
docker run quay.io/kusumach/llmragdemo-load-puppeteer node load.js --url <GRADIO_Service> [--duration <Duration load runs in ms>:default 300000 (5min)] [--delay <Delay between questions in ms>:default 1000] [--browsers <Number of browsers running the load in parallel>:default 1]

```

